{"ast":null,"code":"import { decodeErrPrefix } from './common.js';\nimport { Type } from './token.js';\nimport { jump, quick } from './jump.js';\nconst defaultDecodeOptions = {\n  strict: false,\n  allowIndefinite: true,\n  allowUndefined: true,\n  allowBigInt: true\n};\n\nclass Tokeniser {\n  constructor(data) {\n    let options = arguments.length > 1 && arguments[1] !== undefined ? arguments[1] : {};\n    this.pos = 0;\n    this.data = data;\n    this.options = options;\n  }\n\n  done() {\n    return this.pos >= this.data.length;\n  }\n\n  next() {\n    const byt = this.data[this.pos];\n    let token = quick[byt];\n\n    if (token === undefined) {\n      const decoder = jump[byt];\n\n      if (!decoder) {\n        throw new Error(`${decodeErrPrefix} no decoder for major type ${byt >>> 5} (byte 0x${byt.toString(16).padStart(2, '0')})`);\n      }\n\n      const minor = byt & 31;\n      token = decoder(this.data, this.pos, minor, this.options);\n    }\n\n    this.pos += token.encodedLength;\n    return token;\n  }\n\n}\n\nconst DONE = Symbol.for('DONE');\nconst BREAK = Symbol.for('BREAK');\n\nfunction tokenToArray(token, tokeniser, options) {\n  const arr = [];\n\n  for (let i = 0; i < token.value; i++) {\n    const value = tokensToObject(tokeniser, options);\n\n    if (value === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n\n      throw new Error(`${decodeErrPrefix} got unexpected break to lengthed array`);\n    }\n\n    if (value === DONE) {\n      throw new Error(`${decodeErrPrefix} found array but not enough entries (got ${i}, expected ${token.value})`);\n    }\n\n    arr[i] = value;\n  }\n\n  return arr;\n}\n\nfunction tokenToMap(token, tokeniser, options) {\n  const useMaps = options.useMaps === true;\n  const obj = useMaps ? undefined : {};\n  const m = useMaps ? new Map() : undefined;\n\n  for (let i = 0; i < token.value; i++) {\n    const key = tokensToObject(tokeniser, options);\n\n    if (key === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n\n      throw new Error(`${decodeErrPrefix} got unexpected break to lengthed map`);\n    }\n\n    if (key === DONE) {\n      throw new Error(`${decodeErrPrefix} found map but not enough entries (got ${i} [no key], expected ${token.value})`);\n    }\n\n    if (useMaps !== true && typeof key !== 'string') {\n      throw new Error(`${decodeErrPrefix} non-string keys not supported (got ${typeof key})`);\n    }\n\n    const value = tokensToObject(tokeniser, options);\n\n    if (value === DONE) {\n      throw new Error(`${decodeErrPrefix} found map but not enough entries (got ${i} [no value], expected ${token.value})`);\n    }\n\n    if (useMaps) {\n      m.set(key, value);\n    } else {\n      obj[key] = value;\n    }\n  }\n\n  return useMaps ? m : obj;\n}\n\nfunction tokensToObject(tokeniser, options) {\n  if (tokeniser.done()) {\n    return DONE;\n  }\n\n  const token = tokeniser.next();\n\n  if (token.type === Type.break) {\n    return BREAK;\n  }\n\n  if (token.type.terminal) {\n    return token.value;\n  }\n\n  if (token.type === Type.array) {\n    return tokenToArray(token, tokeniser, options);\n  }\n\n  if (token.type === Type.map) {\n    return tokenToMap(token, tokeniser, options);\n  }\n\n  if (token.type === Type.tag) {\n    if (options.tags && typeof options.tags[token.value] === 'function') {\n      const tagged = tokensToObject(tokeniser, options);\n      return options.tags[token.value](tagged);\n    }\n\n    throw new Error(`${decodeErrPrefix} tag not supported (${token.value})`);\n  }\n\n  throw new Error('unsupported');\n}\n\nfunction decode(data, options) {\n  if (!(data instanceof Uint8Array)) {\n    throw new Error(`${decodeErrPrefix} data to decode must be a Uint8Array`);\n  }\n\n  options = Object.assign({}, defaultDecodeOptions, options);\n  const tokeniser = options.tokenizer || new Tokeniser(data, options);\n  const decoded = tokensToObject(tokeniser, options);\n\n  if (decoded === DONE) {\n    throw new Error(`${decodeErrPrefix} did not find any content to decode`);\n  }\n\n  if (decoded === BREAK) {\n    throw new Error(`${decodeErrPrefix} got unexpected break`);\n  }\n\n  if (!tokeniser.done()) {\n    throw new Error(`${decodeErrPrefix} too many terminals, data makes no sense`);\n  }\n\n  return decoded;\n}\n\nexport { Tokeniser, tokensToObject, decode };","map":{"version":3,"names":["decodeErrPrefix","Type","jump","quick","defaultDecodeOptions","strict","allowIndefinite","allowUndefined","allowBigInt","Tokeniser","constructor","data","options","pos","done","length","next","byt","token","undefined","decoder","Error","toString","padStart","minor","encodedLength","DONE","Symbol","for","BREAK","tokenToArray","tokeniser","arr","i","value","tokensToObject","Infinity","tokenToMap","useMaps","obj","m","Map","key","set","type","break","terminal","array","map","tag","tags","tagged","decode","Uint8Array","Object","assign","tokenizer","decoded"],"sources":["/home/salex/Blockchain/Bootcamp-repositorio/32-DApp con React - Marketplace de NFTs/node_modules/cborg/esm/lib/decode.js"],"sourcesContent":["import { decodeErrPrefix } from './common.js';\nimport { Type } from './token.js';\nimport {\n  jump,\n  quick\n} from './jump.js';\nconst defaultDecodeOptions = {\n  strict: false,\n  allowIndefinite: true,\n  allowUndefined: true,\n  allowBigInt: true\n};\nclass Tokeniser {\n  constructor(data, options = {}) {\n    this.pos = 0;\n    this.data = data;\n    this.options = options;\n  }\n  done() {\n    return this.pos >= this.data.length;\n  }\n  next() {\n    const byt = this.data[this.pos];\n    let token = quick[byt];\n    if (token === undefined) {\n      const decoder = jump[byt];\n      if (!decoder) {\n        throw new Error(`${ decodeErrPrefix } no decoder for major type ${ byt >>> 5 } (byte 0x${ byt.toString(16).padStart(2, '0') })`);\n      }\n      const minor = byt & 31;\n      token = decoder(this.data, this.pos, minor, this.options);\n    }\n    this.pos += token.encodedLength;\n    return token;\n  }\n}\nconst DONE = Symbol.for('DONE');\nconst BREAK = Symbol.for('BREAK');\nfunction tokenToArray(token, tokeniser, options) {\n  const arr = [];\n  for (let i = 0; i < token.value; i++) {\n    const value = tokensToObject(tokeniser, options);\n    if (value === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n      throw new Error(`${ decodeErrPrefix } got unexpected break to lengthed array`);\n    }\n    if (value === DONE) {\n      throw new Error(`${ decodeErrPrefix } found array but not enough entries (got ${ i }, expected ${ token.value })`);\n    }\n    arr[i] = value;\n  }\n  return arr;\n}\nfunction tokenToMap(token, tokeniser, options) {\n  const useMaps = options.useMaps === true;\n  const obj = useMaps ? undefined : {};\n  const m = useMaps ? new Map() : undefined;\n  for (let i = 0; i < token.value; i++) {\n    const key = tokensToObject(tokeniser, options);\n    if (key === BREAK) {\n      if (token.value === Infinity) {\n        break;\n      }\n      throw new Error(`${ decodeErrPrefix } got unexpected break to lengthed map`);\n    }\n    if (key === DONE) {\n      throw new Error(`${ decodeErrPrefix } found map but not enough entries (got ${ i } [no key], expected ${ token.value })`);\n    }\n    if (useMaps !== true && typeof key !== 'string') {\n      throw new Error(`${ decodeErrPrefix } non-string keys not supported (got ${ typeof key })`);\n    }\n    const value = tokensToObject(tokeniser, options);\n    if (value === DONE) {\n      throw new Error(`${ decodeErrPrefix } found map but not enough entries (got ${ i } [no value], expected ${ token.value })`);\n    }\n    if (useMaps) {\n      m.set(key, value);\n    } else {\n      obj[key] = value;\n    }\n  }\n  return useMaps ? m : obj;\n}\nfunction tokensToObject(tokeniser, options) {\n  if (tokeniser.done()) {\n    return DONE;\n  }\n  const token = tokeniser.next();\n  if (token.type === Type.break) {\n    return BREAK;\n  }\n  if (token.type.terminal) {\n    return token.value;\n  }\n  if (token.type === Type.array) {\n    return tokenToArray(token, tokeniser, options);\n  }\n  if (token.type === Type.map) {\n    return tokenToMap(token, tokeniser, options);\n  }\n  if (token.type === Type.tag) {\n    if (options.tags && typeof options.tags[token.value] === 'function') {\n      const tagged = tokensToObject(tokeniser, options);\n      return options.tags[token.value](tagged);\n    }\n    throw new Error(`${ decodeErrPrefix } tag not supported (${ token.value })`);\n  }\n  throw new Error('unsupported');\n}\nfunction decode(data, options) {\n  if (!(data instanceof Uint8Array)) {\n    throw new Error(`${ decodeErrPrefix } data to decode must be a Uint8Array`);\n  }\n  options = Object.assign({}, defaultDecodeOptions, options);\n  const tokeniser = options.tokenizer || new Tokeniser(data, options);\n  const decoded = tokensToObject(tokeniser, options);\n  if (decoded === DONE) {\n    throw new Error(`${ decodeErrPrefix } did not find any content to decode`);\n  }\n  if (decoded === BREAK) {\n    throw new Error(`${ decodeErrPrefix } got unexpected break`);\n  }\n  if (!tokeniser.done()) {\n    throw new Error(`${ decodeErrPrefix } too many terminals, data makes no sense`);\n  }\n  return decoded;\n}\nexport {\n  Tokeniser,\n  tokensToObject,\n  decode\n};"],"mappings":"AAAA,SAASA,eAAT,QAAgC,aAAhC;AACA,SAASC,IAAT,QAAqB,YAArB;AACA,SACEC,IADF,EAEEC,KAFF,QAGO,WAHP;AAIA,MAAMC,oBAAoB,GAAG;EAC3BC,MAAM,EAAE,KADmB;EAE3BC,eAAe,EAAE,IAFU;EAG3BC,cAAc,EAAE,IAHW;EAI3BC,WAAW,EAAE;AAJc,CAA7B;;AAMA,MAAMC,SAAN,CAAgB;EACdC,WAAW,CAACC,IAAD,EAAqB;IAAA,IAAdC,OAAc,uEAAJ,EAAI;IAC9B,KAAKC,GAAL,GAAW,CAAX;IACA,KAAKF,IAAL,GAAYA,IAAZ;IACA,KAAKC,OAAL,GAAeA,OAAf;EACD;;EACDE,IAAI,GAAG;IACL,OAAO,KAAKD,GAAL,IAAY,KAAKF,IAAL,CAAUI,MAA7B;EACD;;EACDC,IAAI,GAAG;IACL,MAAMC,GAAG,GAAG,KAAKN,IAAL,CAAU,KAAKE,GAAf,CAAZ;IACA,IAAIK,KAAK,GAAGf,KAAK,CAACc,GAAD,CAAjB;;IACA,IAAIC,KAAK,KAAKC,SAAd,EAAyB;MACvB,MAAMC,OAAO,GAAGlB,IAAI,CAACe,GAAD,CAApB;;MACA,IAAI,CAACG,OAAL,EAAc;QACZ,MAAM,IAAIC,KAAJ,CAAW,GAAGrB,eAAiB,8BAA8BiB,GAAG,KAAK,CAAG,YAAYA,GAAG,CAACK,QAAJ,CAAa,EAAb,EAAiBC,QAAjB,CAA0B,CAA1B,EAA6B,GAA7B,CAAmC,GAAvH,CAAN;MACD;;MACD,MAAMC,KAAK,GAAGP,GAAG,GAAG,EAApB;MACAC,KAAK,GAAGE,OAAO,CAAC,KAAKT,IAAN,EAAY,KAAKE,GAAjB,EAAsBW,KAAtB,EAA6B,KAAKZ,OAAlC,CAAf;IACD;;IACD,KAAKC,GAAL,IAAYK,KAAK,CAACO,aAAlB;IACA,OAAOP,KAAP;EACD;;AAtBa;;AAwBhB,MAAMQ,IAAI,GAAGC,MAAM,CAACC,GAAP,CAAW,MAAX,CAAb;AACA,MAAMC,KAAK,GAAGF,MAAM,CAACC,GAAP,CAAW,OAAX,CAAd;;AACA,SAASE,YAAT,CAAsBZ,KAAtB,EAA6Ba,SAA7B,EAAwCnB,OAAxC,EAAiD;EAC/C,MAAMoB,GAAG,GAAG,EAAZ;;EACA,KAAK,IAAIC,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGf,KAAK,CAACgB,KAA1B,EAAiCD,CAAC,EAAlC,EAAsC;IACpC,MAAMC,KAAK,GAAGC,cAAc,CAACJ,SAAD,EAAYnB,OAAZ,CAA5B;;IACA,IAAIsB,KAAK,KAAKL,KAAd,EAAqB;MACnB,IAAIX,KAAK,CAACgB,KAAN,KAAgBE,QAApB,EAA8B;QAC5B;MACD;;MACD,MAAM,IAAIf,KAAJ,CAAW,GAAGrB,eAAiB,yCAA/B,CAAN;IACD;;IACD,IAAIkC,KAAK,KAAKR,IAAd,EAAoB;MAClB,MAAM,IAAIL,KAAJ,CAAW,GAAGrB,eAAiB,4CAA4CiC,CAAG,cAAcf,KAAK,CAACgB,KAAO,GAAzG,CAAN;IACD;;IACDF,GAAG,CAACC,CAAD,CAAH,GAASC,KAAT;EACD;;EACD,OAAOF,GAAP;AACD;;AACD,SAASK,UAAT,CAAoBnB,KAApB,EAA2Ba,SAA3B,EAAsCnB,OAAtC,EAA+C;EAC7C,MAAM0B,OAAO,GAAG1B,OAAO,CAAC0B,OAAR,KAAoB,IAApC;EACA,MAAMC,GAAG,GAAGD,OAAO,GAAGnB,SAAH,GAAe,EAAlC;EACA,MAAMqB,CAAC,GAAGF,OAAO,GAAG,IAAIG,GAAJ,EAAH,GAAetB,SAAhC;;EACA,KAAK,IAAIc,CAAC,GAAG,CAAb,EAAgBA,CAAC,GAAGf,KAAK,CAACgB,KAA1B,EAAiCD,CAAC,EAAlC,EAAsC;IACpC,MAAMS,GAAG,GAAGP,cAAc,CAACJ,SAAD,EAAYnB,OAAZ,CAA1B;;IACA,IAAI8B,GAAG,KAAKb,KAAZ,EAAmB;MACjB,IAAIX,KAAK,CAACgB,KAAN,KAAgBE,QAApB,EAA8B;QAC5B;MACD;;MACD,MAAM,IAAIf,KAAJ,CAAW,GAAGrB,eAAiB,uCAA/B,CAAN;IACD;;IACD,IAAI0C,GAAG,KAAKhB,IAAZ,EAAkB;MAChB,MAAM,IAAIL,KAAJ,CAAW,GAAGrB,eAAiB,0CAA0CiC,CAAG,uBAAuBf,KAAK,CAACgB,KAAO,GAAhH,CAAN;IACD;;IACD,IAAII,OAAO,KAAK,IAAZ,IAAoB,OAAOI,GAAP,KAAe,QAAvC,EAAiD;MAC/C,MAAM,IAAIrB,KAAJ,CAAW,GAAGrB,eAAiB,uCAAuC,OAAO0C,GAAK,GAAlF,CAAN;IACD;;IACD,MAAMR,KAAK,GAAGC,cAAc,CAACJ,SAAD,EAAYnB,OAAZ,CAA5B;;IACA,IAAIsB,KAAK,KAAKR,IAAd,EAAoB;MAClB,MAAM,IAAIL,KAAJ,CAAW,GAAGrB,eAAiB,0CAA0CiC,CAAG,yBAAyBf,KAAK,CAACgB,KAAO,GAAlH,CAAN;IACD;;IACD,IAAII,OAAJ,EAAa;MACXE,CAAC,CAACG,GAAF,CAAMD,GAAN,EAAWR,KAAX;IACD,CAFD,MAEO;MACLK,GAAG,CAACG,GAAD,CAAH,GAAWR,KAAX;IACD;EACF;;EACD,OAAOI,OAAO,GAAGE,CAAH,GAAOD,GAArB;AACD;;AACD,SAASJ,cAAT,CAAwBJ,SAAxB,EAAmCnB,OAAnC,EAA4C;EAC1C,IAAImB,SAAS,CAACjB,IAAV,EAAJ,EAAsB;IACpB,OAAOY,IAAP;EACD;;EACD,MAAMR,KAAK,GAAGa,SAAS,CAACf,IAAV,EAAd;;EACA,IAAIE,KAAK,CAAC0B,IAAN,KAAe3C,IAAI,CAAC4C,KAAxB,EAA+B;IAC7B,OAAOhB,KAAP;EACD;;EACD,IAAIX,KAAK,CAAC0B,IAAN,CAAWE,QAAf,EAAyB;IACvB,OAAO5B,KAAK,CAACgB,KAAb;EACD;;EACD,IAAIhB,KAAK,CAAC0B,IAAN,KAAe3C,IAAI,CAAC8C,KAAxB,EAA+B;IAC7B,OAAOjB,YAAY,CAACZ,KAAD,EAAQa,SAAR,EAAmBnB,OAAnB,CAAnB;EACD;;EACD,IAAIM,KAAK,CAAC0B,IAAN,KAAe3C,IAAI,CAAC+C,GAAxB,EAA6B;IAC3B,OAAOX,UAAU,CAACnB,KAAD,EAAQa,SAAR,EAAmBnB,OAAnB,CAAjB;EACD;;EACD,IAAIM,KAAK,CAAC0B,IAAN,KAAe3C,IAAI,CAACgD,GAAxB,EAA6B;IAC3B,IAAIrC,OAAO,CAACsC,IAAR,IAAgB,OAAOtC,OAAO,CAACsC,IAAR,CAAahC,KAAK,CAACgB,KAAnB,CAAP,KAAqC,UAAzD,EAAqE;MACnE,MAAMiB,MAAM,GAAGhB,cAAc,CAACJ,SAAD,EAAYnB,OAAZ,CAA7B;MACA,OAAOA,OAAO,CAACsC,IAAR,CAAahC,KAAK,CAACgB,KAAnB,EAA0BiB,MAA1B,CAAP;IACD;;IACD,MAAM,IAAI9B,KAAJ,CAAW,GAAGrB,eAAiB,uBAAuBkB,KAAK,CAACgB,KAAO,GAAnE,CAAN;EACD;;EACD,MAAM,IAAIb,KAAJ,CAAU,aAAV,CAAN;AACD;;AACD,SAAS+B,MAAT,CAAgBzC,IAAhB,EAAsBC,OAAtB,EAA+B;EAC7B,IAAI,EAAED,IAAI,YAAY0C,UAAlB,CAAJ,EAAmC;IACjC,MAAM,IAAIhC,KAAJ,CAAW,GAAGrB,eAAiB,sCAA/B,CAAN;EACD;;EACDY,OAAO,GAAG0C,MAAM,CAACC,MAAP,CAAc,EAAd,EAAkBnD,oBAAlB,EAAwCQ,OAAxC,CAAV;EACA,MAAMmB,SAAS,GAAGnB,OAAO,CAAC4C,SAAR,IAAqB,IAAI/C,SAAJ,CAAcE,IAAd,EAAoBC,OAApB,CAAvC;EACA,MAAM6C,OAAO,GAAGtB,cAAc,CAACJ,SAAD,EAAYnB,OAAZ,CAA9B;;EACA,IAAI6C,OAAO,KAAK/B,IAAhB,EAAsB;IACpB,MAAM,IAAIL,KAAJ,CAAW,GAAGrB,eAAiB,qCAA/B,CAAN;EACD;;EACD,IAAIyD,OAAO,KAAK5B,KAAhB,EAAuB;IACrB,MAAM,IAAIR,KAAJ,CAAW,GAAGrB,eAAiB,uBAA/B,CAAN;EACD;;EACD,IAAI,CAAC+B,SAAS,CAACjB,IAAV,EAAL,EAAuB;IACrB,MAAM,IAAIO,KAAJ,CAAW,GAAGrB,eAAiB,0CAA/B,CAAN;EACD;;EACD,OAAOyD,OAAP;AACD;;AACD,SACEhD,SADF,EAEE0B,cAFF,EAGEiB,MAHF"},"metadata":{},"sourceType":"module"}